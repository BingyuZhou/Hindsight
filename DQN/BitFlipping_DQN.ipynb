{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bit flipping game with DQN solver\n",
    "\n",
    "This is the implementation of the DQN solver for the bit flipping game in [**Hindsight Experience Replay**](https://arxiv.org/abs/1707.01495).\n",
    "\n",
    "**Rerefence**:\n",
    "\n",
    "1. Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, Wojciech Zaremba, Hindsight Experience Replay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bitflipping import bitflipping as bf\n",
    "from DQN import DQN\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 20]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the bit flipping game environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = np.array([0,1])\n",
    "goal = np.ones((2,))\n",
    "n = 4\n",
    "bf_env = bf(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up the DQN neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2*n))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "\n",
    "hid = [256]\n",
    "agent = DQN(x, hid, n, discount=0.98, eps=0.8, tau = 0.95, replay_buffer_size=1e5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cycle 0: loss is 0.0316\n",
      "Epoch 0 Cycle 1: loss is 0.0282\n",
      "Epoch 0 Cycle 2: loss is 0.0283\n",
      "Epoch 0 Cycle 3: loss is 0.0711\n",
      "Epoch 0 Cycle 4: loss is 0.0206\n",
      "Epoch 0 Cycle 5: loss is 0.0538\n",
      "Epoch 0 Cycle 6: loss is 0.0317\n",
      "Epoch 0 Cycle 7: loss is 0.0487\n",
      "Epoch 0 Cycle 8: loss is 0.0508\n",
      "Epoch 0 Cycle 9: loss is 0.0369\n",
      "Epoch 0 Cycle 10: loss is 0.0566\n",
      "Epoch 0 Cycle 11: loss is 0.0608\n",
      "Epoch 0 Cycle 12: loss is 0.0414\n",
      "Epoch 0 Cycle 13: loss is 0.0436\n",
      "Epoch 0 Cycle 14: loss is 0.0245\n",
      "Epoch 0 Cycle 15: loss is 0.0485\n",
      "Epoch 0 Cycle 16: loss is 0.0486\n",
      "Epoch 0 Cycle 17: loss is 0.0521\n",
      "Epoch 0 Cycle 18: loss is 0.106\n",
      "Epoch 0 Cycle 19: loss is 0.0808\n",
      "Epoch 0 Cycle 20: loss is 0.056\n",
      "Epoch 0 Cycle 21: loss is 0.114\n",
      "Epoch 0 Cycle 22: loss is 0.0613\n",
      "Epoch 0 Cycle 23: loss is 0.0642\n",
      "Epoch 0 Cycle 24: loss is 0.0641\n"
     ]
    }
   ],
   "source": [
    "losses, success_all = agent.train_Q(x, y, epoch=8, cycles=50, episode=16, iteration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, '/tmp/model.ckpt')\n",
    "    \n",
    "    success = 0\n",
    "    for i in range(100):\n",
    "        \n",
    "        bf_env.reset()\n",
    "\n",
    "        for i in range(n):\n",
    "            X = np.concatenate((bf_env.state.reshape((1,-1)),bf_env.goal.reshape((1,-1))), axis=1)\n",
    "            Q = sess.run(agent.targetModel, feed_dict={x: X})\n",
    "            action = np.argmax(Q)\n",
    "            bf_env.update_state(action)\n",
    "            if (bf_env.reward(bf_env.state)==0):\n",
    "                print('Success! state:{0}\\t Goal state:{1}'.format(bf_env.state, bf_env.goal))\n",
    "                success += 1\n",
    "                break\n",
    "            elif (i==n-1):\n",
    "                print('Fail! state:{0}\\t Goal state:{1}'.format(bf_env.state, bf_env.goal))\n",
    "                \n",
    "    print('Success rate {}%'.format(success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[1,2,3,2,1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
